{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploy on videos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuNL7IIbLDi6",
        "colab_type": "text"
      },
      "source": [
        "###deploy model and use it to detect wearing mask in video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GMZNxiLZqnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "7878b170-5caf-485d-8a1e-2b27cd995671"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrRE-DZX1j-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.video import VideoStream\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5_j9BVP0nLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIR_FACE = \"/content/drive/My Drive/face_detector\"\n",
        "MASK_MODEL = \"/content/drive/My Drive/Mask_Detector_model.model\"\n",
        "Input_Video_Path = \"/content/drive/My Drive/sample video.mp4\"\n",
        "Output_Video_Path = \"/content/drive/My Drive/outputvideo.mp4\"\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ph1jm-W1nSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
        "    (h, w) = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),\n",
        "                                 (104.0, 177.0, 123.0))\n",
        "\n",
        "    faceNet.setInput(blob)\n",
        "    detections = faceNet.forward()\n",
        "\n",
        "\n",
        "    faces = []\n",
        "    locs = []\n",
        "    preds = []\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "\n",
        "        if confidence > 0.5:\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "            (startX, startY) = (max(0, startX), max(0, startY))\n",
        "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "            face = frame[startY:endY, startX:endX]\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "            face = cv2.resize(face, (224, 224))\n",
        "            face = img_to_array(face)\n",
        "            face = preprocess_input(face)\n",
        "\n",
        "            faces.append(face)\n",
        "            locs.append((startX, startY, endX, endY))\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        faces = np.array(faces, dtype=\"float32\")\n",
        "        preds = maskNet.predict(faces, batch_size=32)\n",
        "\n",
        "    return (locs, preds)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BtA4fCqfuLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6dcd5481-befb-4432-eb0b-1fee1b97c9a9"
      },
      "source": [
        "print(\"loading face detector model...\")\n",
        "prototxtPath = os.path.sep.join([DIR_FACE, \"deploy.prototxt\"])\n",
        "weightsPath = os.path.sep.join([DIR_FACE, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
        "\n",
        "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "print(\"loading face mask detector model...\")\n",
        "maskNet = load_model(MASK_MODEL)\n",
        "\n",
        "import_movie = 0\n",
        "input_movie = cv2.VideoCapture(Input_Video_Path)\n",
        "length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "codec = cv2.VideoWriter_fourcc(*'MP4V') #codec\n",
        "fps = int(input_movie.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(input_movie.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(input_movie.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "output_movie = cv2.VideoWriter(Output_Video_Path, codec, fps, (frame_width, frame_height))\n",
        "\n",
        "\n",
        "# Write the resulting image to the output video file\n",
        "\n",
        "frame_number = 0\n",
        "\n",
        "# loop over the frames from the video stream\n",
        "\n",
        "while True:\n",
        "    # grab the frame from the threaded video stream and resize it\n",
        "    # to have a maximum width of 400 pixels\n",
        "    ret, frame = input_movie.read()\n",
        "    # frame = imutils.resize(frame, width=400)\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    # detect faces in the frame and determine if they are wearing a\n",
        "    # face mask or not\n",
        "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
        "    # loop over the detected face locations and their corresponding locations\n",
        "    for (box, pred) in zip(locs, preds):\n",
        "        # unpack the bounding box and predictions\n",
        "        (startX, startY, endX, endY) = box\n",
        "        (mask, withoutMask) = pred\n",
        "\n",
        "        # determine the class label and color we'll use to draw\n",
        "        # the bounding box and text\n",
        "        if mask > withoutMask:\n",
        "            label = \"Safe\"\n",
        "            color = (0, 255, 0)\n",
        "        else:\n",
        "            label = \"Not Safe\"\n",
        "            color = (0, 0, 255)\n",
        "\n",
        "        # include the probability in the label\n",
        "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "        # display the label and bounding box rectangle on the output\n",
        "        # frame\n",
        "        cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "    frame_number += 1\n",
        "    output_movie.write(frame)\n",
        "\n",
        "print(\"done\")\n",
        "input_movie.release()\n",
        "output_movie.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading face detector model...\n",
            "loading face mask detector model...\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyJ3TVwdZ0a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}